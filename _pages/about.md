---
title: "About"
permalink: /about/
layout: single
---

## Yeon-Soo Lim

### WORK EXPERIENCE  
- AIR Lab@42dot(Hyundai Global Software Center) (2022.09 ~ )
- AIR Lab@Hyundai Motor Company (2022.03 ~ 2022.09)

### Education  
- M.S., in Computer Engineering, Kyung Hee University (2020.03 ~ 2022.02)
- B.S., in Computer Engineering, Kyung Hee University (2014.03 ~ 2020.02)

### Technical Skills  
- Hand-on experience in applying PyTorch, NLP tools (NLTK, etc.) and open libraries (huggingface, fairseq, etc.) for Korean NLP tasks
- Experience in several NLP tasks with Non-autoregressive decoding, text summarization and Natural Language Understanding
- Build ML pipeline system use Airflow, MLflow, Docker and kubernetes
- Python: Skillful, C++: Middle level

### Research Experience  
Non-Autoregressive Machine Translation (2020.10 ~ 2022.01)  
- Research Non-Autoregressive Decoding technology for machine translation
- Proposes a novel machine translation model which changes the length of a target sentence iteratively to an optimal length
- Propsed model expand or delete token to find optimal target sentence length

Korean single and multi-document summary (2020.03 ~ 2021.12)  
- Develop a topic-centric text summarization model with statistical attribute model. Apply PPLM to the text summarization for generate a topic-centric summary.
- Develop a text summarization model using BART
- Propose post-processing method to merge semantically similar summaries for multi-document summarization.

Korean dialogue model based on deep learning (2020.03 ~ 2020.12)  
- Research on dialogue generation technology in the form of a single model for multiple domains. Using Continual Learning, a single conversational model can respond to multiple domains.
- Develop a conversation model using seq2seq structure and GPT2 that reflects the keyword score of tokens measured by the keyword extractor.

### Publications  
International Journal Articles  
- **Yeon-Soo Lim**, Eun-Ju Park, Hyun-Je Song and Seong-Bae Park. A Non-Autoregressive Neural Machine Translation Model with Iterative Length Update of Target Sentence, *IEEE Access*, vol. 10, pp.43341-43350, 2022.  
- So-Eon Kim, **Yeon-Soo Lim** and Seong-Bae Parkk. Strong Influence of Responses in Training Dialogue Response Generator, *Applied Sciences*, 11(16), 7415, 2021.

Domestic Conference Papers  
- **Yeon-Soo Lim**, BongMin Kim, Choong Seon Hong, and Seong-Bae Park. 2021.  Hate Speech Detection Model using Noise Self-training. In *Proceedings of the Korea Computer Congress 2021*, pp. 376-378, 2021.
- Sunggoo Kwon, **Yeon-Soo Lim**, and Seong-Bae Park. The Study on Korean Single Document Summarization Using Pre-trained Language Models. In *Proceedings of the Korea Computer Congress 2021*, pp. 379-381, 2021.
- **Yeon-Soo Lim**, So-Eon Kim, Bong-Min Kim, Heejae Jung, and Seong-Bae Park. A Query-aware Dialog Model for Open-domain Dialog. In *Proceedings of the 32th Annual Conference on Human and Cognitive Language Technology*, pp. 274-279, 2020.

### Patents  
Domestic Patent (in Korean)
- Cheoneum Park, **Yeonsoo Lim**. Method, Apparatus, and Computer-readable Medium for Error Correction on Document Summarization. 2023/03, (application umber) 10-2023-0033520.
